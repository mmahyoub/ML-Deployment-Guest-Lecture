{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Predictive Model: Development and Deployment\n",
    "### Mohammed Mahyoub \n",
    "This Jupyter Notebook is a companion lab for a guest lecture about machine learning deployment at University of Alabama at Birmingham, Alabama, USA. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required packages for the project environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing packages \n",
    "%pip install pandas scipy numpy scikit-learn joblib flasgger flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "parent_folder = os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a diabetes dataset from Microsoft Machine Learning data repository. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('https://aka.ms/diabetes-data')\n",
    "dataset.drop('PatientID', axis = 1, inplace = True)\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Diabetic'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Sample a subset of the data for deployment testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_dataset = dataset.sample(n = 100)\n",
    "deployment_dataset.drop('Diabetic', axis = 'columns', inplace = True)\n",
    "deployment_dataset.to_csv('deployment_dataset.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Save dev dataset to current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('diabetes.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Development folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil\n",
    "\n",
    "dev_folder = 'Development'\n",
    "os.makedirs(dev_folder, exist_ok = True)\n",
    "\n",
    "shutil.copy( os.path.join(parent_folder, 'diabetes.csv'), os.path.join(parent_folder, dev_folder, 'diabetes.csv'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $parent_folder/$dev_folder/train_diabetes.py\n",
    "\n",
    "# Packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "\n",
    "# Dataset\n",
    "dataset = pd.read_csv('./diabetes.csv')\n",
    "X = dataset.drop('Diabetic', axis = 'columns')\n",
    "y = dataset['Diabetic']\n",
    "\n",
    "# Preprocessing \n",
    "numeric_features = list(range(X.shape[1]))\n",
    "numeric_transformer = Pipeline(steps=[('scaler', MinMaxScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features)])\n",
    "\n",
    "# Training \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('randomforest', RandomForestClassifier())])\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "model_performance = {'Description': 'Diabetes prediction model. Version 1.',\n",
    "                     'Author': 'Mohammed Mahyoub',\n",
    "                     'Metrics': {'Accuracy': round(accuracy_score(y_test,y_hat), 2),\n",
    "                     'AUC': round(roc_auc_score(y_test, model.predict_proba(X_test)[:,1]), 2),\n",
    "                     'f1-score': round(f1_score(y_test, y_hat), 2),\n",
    "                     'Precision': round(precision_score(y_test, y_hat), 2),\n",
    "                     'Recall': round(recall_score(y_test, y_hat), 2)}\n",
    "                        }\n",
    "perf_file = open('./model_performance.json', 'w')\n",
    "json.dump(model_performance, perf_file, indent = 4)                                 \n",
    "perf_file.close()\n",
    "# Save trained pipeline\n",
    "joblib.dump(model, './diabetes-predict.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(os.path.join(parent_folder, dev_folder))\n",
    "%run train_diabetes.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(parent_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deployment -  Flask and Swagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Deployment folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil\n",
    "\n",
    "dep_folder = 'Deployment'\n",
    "os.makedirs(dep_folder, exist_ok = True)\n",
    "\n",
    "model_artificat_loc = os.path.join(parent_folder, dev_folder, 'diabetes-predict.pkl')\n",
    "test_dataset_loc = os.path.join(parent_folder, 'deployment_dataset.csv')\n",
    "\n",
    "shutil.copy(model_artificat_loc, os.path.join(parent_folder, dep_folder, 'diabetes-predict.pkl'))\n",
    "shutil.copy(test_dataset_loc, os.path.join(parent_folder, dep_folder, 'test_dataset.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Deployment code: API and scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $parent_folder/$dep_folder/deploy_diabetes.py\n",
    "\n",
    "# Packages \n",
    "from flask import Flask, request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import flasgger \n",
    "from flasgger import Swagger\n",
    "\n",
    "\n",
    "# Create app and wrap it with Swagger framework\n",
    "app = Flask(__name__)\n",
    "Swagger(app)\n",
    "\n",
    "# Load model\n",
    "model = joblib.load('./diabetes-predict.pkl')\n",
    "\n",
    "# On-demand prediction \n",
    "@app.route('/predict', methods = [\"Get\"])\n",
    "def ondemand_predict():\n",
    "    \"\"\"\n",
    "    Endpoint for ondemand diabetes prediction. Single entry.\n",
    "    ---\n",
    "    parameters:\n",
    "        - name: Pregnancies\n",
    "          in: query\n",
    "          type: number\n",
    "          required: true\n",
    "        - name: Plasma Glucose\n",
    "          in: query\n",
    "          type: number\n",
    "          required: true  \n",
    "        - name: Diastolic Blood Pressure\n",
    "          in: query\n",
    "          type: number\n",
    "          required: true\n",
    "        - name: Triceps Thickness\n",
    "          in: query\n",
    "          type: number\n",
    "          required: true\n",
    "        - name: Serum Insulin\n",
    "          in: query\n",
    "          type: number\n",
    "          required: true\n",
    "        - name: BMI\n",
    "          in: query\n",
    "          type: number\n",
    "          required: true\n",
    "        - name: Diabetes Pedigree \n",
    "          in: query\n",
    "          type: number\n",
    "          required: true\n",
    "        - name: Age\n",
    "          in: query\n",
    "          type: number\n",
    "          required: true\n",
    "    responses:\n",
    "        500:\n",
    "            description: \"Prediction\"\n",
    "\n",
    "    \"\"\"\n",
    "    Pregnancies = float(request.args.get(\"Pregnancies\"))\n",
    "    PlasmaGlucose = float(request.args.get(\"Plasma Glucose\"))\n",
    "    DiastolicBloodPressure = float(request.args.get(\"Diastolic Blood Pressure\"))\n",
    "    TricepsThickness = float(request.args.get(\"Triceps Thickness\"))\n",
    "    SerumInsulin = float(request.args.get(\"Serum Insulin\"))\n",
    "    BMI = float(request.args.get(\"BMI\"))\n",
    "    DiabetesPedigree = float(request.args.get(\"Diabetes Pedigree\"))\n",
    "    Age = float(request.args.get(\"Age\"))\n",
    "\n",
    "    input_features = np.array([[\n",
    "        Pregnancies,\n",
    "        PlasmaGlucose,\n",
    "        DiastolicBloodPressure,\n",
    "        TricepsThickness,\n",
    "        SerumInsulin,\n",
    "        BMI,\n",
    "        DiabetesPedigree,\n",
    "        Age]])\n",
    "\n",
    "    prediction = model.predict(input_features)\n",
    "\n",
    "    labels = {0: 'Non-Diabetic', 1: 'Diabetic'}\n",
    "\n",
    "    return labels[prediction[0]]\n",
    "\n",
    "@app.route('/predict_batch', methods = [\"Post\"])\n",
    "def batch_predict():\n",
    "  \"\"\"\n",
    "  Endpoint for batch prediction. Batch of patients.\n",
    "  ---\n",
    "  parameters:\n",
    "    - name: file\n",
    "      in: formData\n",
    "      type: file\n",
    "      required: true\n",
    "  responses:\n",
    "      500:\n",
    "        description: \"Batch Prediction\"\n",
    "  \"\"\"\n",
    "\n",
    "  batch_df = pd.read_csv(request.files.get(\"file\"))\n",
    "  predictions = model.predict(batch_df)\n",
    "  labels = {0: 'Non-Diabetic', 1: 'Diabetic'}\n",
    "  predictions = [labels[p] for p in predictions]\n",
    "  \n",
    "  return str(predictions)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug = True, host = '0.0.0.0', port = 80)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run deployment script\n",
    "> Note: Go to the suggested link and add /apidocs to access the web app. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(parent_folder, dep_folder))\n",
    "%run deploy_diabetes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(parent_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deployment - Docker Container "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Requirements (packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip freeze > $parent_folder/$dep_folder/requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $parent_folder/$dep_folder/Dockerfile \n",
    "\n",
    "FROM python:3.9\n",
    "COPY . usr/webapp/diabetesapp\n",
    "EXPOSE 80\n",
    "WORKDIR usr/webapp/diabetesapp\n",
    "RUN pip install -r requirements.txt \n",
    "CMD python deploy_diabetes.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Build image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note: for Windows you can use the terminal or CMD command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker build -t diabetes_webapp ./Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run container"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note: Add /apidocs to the url provider during running the docker image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container run -p 80:80 diabetes_webapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker container ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker stop distracted_tesla   # Change the name of the container, eatch time will be different. Get correct name from the NAMES option above. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment in the Cloud"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Microsoft Azure to build our image and register the container in Azure Container Registry. Then, we will be building a webapp uisng Azure APP services. Similar approach could be used with other cloud computation providers (GCP, AWS, etc.). Usually, we would use Azure Machine Learning to build and deploy our ML models as managed real-time or batch endpoints. \n",
    "\n",
    "This part assumes that you have a functioning Azure subscription. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Log in to Azure portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az login "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a resource group for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "az group create -l eastus -n rg-ml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a container registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az acr create -n crmldeployment -g rg-ml --admin-enabled true --sku Standard "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Build the docker image from the artificats saved in the Deployment folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az acr build -t diabeteswebappcr:{{.Run.ID}} -r crmldeployment ./Deployment "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. List the repositories and tags in the container registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "az acr repository list -n crmldeployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az acr repository show-tags -n crmldeployment --repository diabeteswebappcr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create a webapp plan. We will create the free plan for the sake of this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az appservice plan create -g rg-ml -n depplan --is-linux --sku F1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Create the webapp to be hosted on Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "az webapp create -g rg-ml -p depplan -n diabeteswebappmm -i crmldeployment.azurecr.io/diabeteswebappcr:ca1  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Access the webapp\n",
    "> Note: You need to add \"/apidocs\" to the url to access the Swagger API. Initially, you will get an access error so you need to add the \"/apidocs\" similar to what we did on premise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az webapp browse --name diabeteswebappmm -g rg-ml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Delete the resource group to cleanup resources. I am doing this step because I create the webapp for the sake of illustration and don`t want to incur costs beyond this lecutre. In real scenario, this step will destroy all your efforts (Be Careful!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az group delete -g rg-ml --no-wait --yes --force-deletion-types Microsoft.Compute/virtualMachines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> Thank you! </h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bff37cf47c7d7b7e8d8dbb062791c98487308dc609cf011dd0ee363995c08e7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
